# FILE: src/test/test_iclr_scraper.py
#
# -----------------------------------------------------------------------------
# [ç‹¬ç«‹çš„ ICLR çˆ¬è™«æµ‹è¯•è„šæœ¬ - ä¸¤é˜¶æ®µæµ‹è¯•]
#
# ç›®  çš„:
#   å¿«é€Ÿã€ç‹¬ç«‹åœ°æµ‹è¯• IclrScraper çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¹¶éªŒè¯ä¸¤ç§ä¸åŒçš„æ•°æ®è·å–æ¨¡å¼ã€‚
#
# åŠŸ  èƒ½:
#   1.  **é˜¶æ®µä¸€ (å¹¿åº¦æµ‹è¯•)**:
#       - ä¸ºæ¯ä¸€å¹´ä»½æŠ“å–æœ€å¤š 100 ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ç­‰ï¼‰ã€‚
#       - ä¸è·å–å®¡ç¨¿æ„è§å’ŒPDFé“¾æ¥ï¼Œä»¥ä¿è¯é€Ÿåº¦ã€‚
#       - éªŒè¯å¤§è§„æ¨¡æ•°æ®æ‹‰å–çš„åŸºæœ¬æµç¨‹ã€‚
#
#   2.  **é˜¶æ®µäºŒ (æ·±åº¦æµ‹è¯•)**:
#       - ä¸ºæ¯ä¸€å¹´ä»½æŠ“å– 3 ç¯‡è®ºæ–‡çš„ **å…¨éƒ¨** ä¿¡æ¯ã€‚
#       - **è·å–å®¡ç¨¿æ„è§å’ŒPDFé“¾æ¥**ã€‚
#       - éªŒè¯è€—æ—¶è¾ƒé•¿ã€é€»è¾‘è¾ƒå¤æ‚çš„æ•°æ®æå–åŠŸèƒ½ã€‚
#
# å¦‚ä½•è¿è¡Œ:
#   åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ:
#   python -m src.test.test_iclr_scraper
#
# -----------------------------------------------------------------------------

import sys
import time
from pathlib import Path
from pprint import pprint
from dataclasses import asdict

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„ä¸­ï¼Œä»¥ç¡®ä¿èƒ½å¤Ÿå¯¼å…¥ src ä¸‹çš„æ¨¡å—
# resolve() ä½¿è·¯å¾„æ›´æ˜ç¡®ï¼Œå¹¶æ£€æŸ¥è·¯å¾„æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ 
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

from src.scrapers.iclr_scraper import IclrScraper
from src.crawlers.config import get_logger
from src.crawlers.models import Paper

# --- æµ‹è¯•é…ç½® ---
YEARS_TO_TEST = [2022, 2023, 2024, 2025]
METADATA_PAPER_LIMIT = 100  # é˜¶æ®µä¸€ï¼šå…ƒæ•°æ®æµ‹è¯•çš„è®ºæ–‡æ•°é‡
FULL_DETAIL_PAPER_LIMIT = 3  # é˜¶æ®µäºŒï¼šå®Œæ•´ä¿¡æ¯æµ‹è¯•çš„è®ºæ–‡æ•°é‡

# å°†é…ç½®ä¿¡æ¯é›†ä¸­ç®¡ç†ï¼Œä¾¿äºæœªæ¥æ‰©å±•å’Œç»´æŠ¤
# OpenReview åœ¨ 2024 å¹´å·¦å³å¼€å§‹æ¨å¹¿ä½¿ç”¨ V2 API
CONFIG_MAP = {
    2022: {'api_version': 'v1'},
    2023: {'api_version': 'v1'},
    2024: {'api_version': 'v2'},
    2025: {'api_version': 'v2'},
}


def run_test():
    """æ‰§è¡Œ ICLR çˆ¬è™«çš„ä¸¤é˜¶æ®µæµ‹è¯•å¥—ä»¶"""
    logger = get_logger("ICLR_Scraper_Test")
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ ICLR Scraper ç‹¬ç«‹æµ‹è¯• (ä¸¤é˜¶æ®µæ¨¡å¼)...")
    print(f"   å°†æµ‹è¯•å¹´ä»½: {YEARS_TO_TEST}")
    print(f"   é˜¶æ®µä¸€: æœ€å¤šè·å– {METADATA_PAPER_LIMIT} ç¯‡è®ºæ–‡çš„å…ƒæ•°æ®")
    print(f"   é˜¶æ®µäºŒ: æœ€å¤šè·å– {FULL_DETAIL_PAPER_LIMIT} ç¯‡è®ºæ–‡çš„å®Œæ•´ä¿¡æ¯ (å«å®¡ç¨¿æ„è§)")
    print("=" * 80 + "\n")

    for year in YEARS_TO_TEST:
        print(f"\n" + "â”€" * 40 + f" [ ICLR {year} ] " + "â”€" * 40)

        year_config = CONFIG_MAP.get(year)
        if not year_config:
            print(f"  [!] è·³è¿‡ ICLR {year}ï¼Œå› ä¸ºæœªåœ¨ CONFIG_MAP ä¸­æ‰¾åˆ°é…ç½®ã€‚")
            continue

        base_task_info = {
            'conference': 'ICLR',
            'year': year,
            'source_type': 'iclr',
            'venue_id': f'ICLR.cc/{year}/Conference',
            'api_version': year_config['api_version'],
        }

        # --- é˜¶æ®µä¸€: å¹¿åº¦æµ‹è¯• (ä»…å…ƒæ•°æ®) ---
        print(f"  [â–¶ Phase 1/2] æ­£åœ¨æµ‹è¯•: å…ƒæ•°æ®è·å– (Limit: {METADATA_PAPER_LIMIT})")
        try:
            task_info_meta = base_task_info.copy()
            task_info_meta.update({
                'limit': METADATA_PAPER_LIMIT,
                'fetch_reviews': False
            })

            logger.info(f"ä¸º ICLR {year} (å…ƒæ•°æ®æµ‹è¯•) ç”Ÿæˆçš„é…ç½®: {task_info_meta}")

            scraper_meta = IclrScraper(task_info_meta, logger)
            results_meta = scraper_meta.scrape()

            if results_meta:
                print(f"    [âœ” SUCCESS] æˆåŠŸè·å– {len(results_meta)} ç¯‡è®ºæ–‡çš„å…ƒæ•°æ®ã€‚")
                print("    --- æ ·æœ¬æ•°æ® (ç¬¬ä¸€ç¯‡ï¼Œä¸å«å®¡ç¨¿æ„è§) ---")
                pprint(asdict(results_meta[0]), indent=4, width=100)
                print("    --------------------------------------\n")
            else:
                print(f"    [âš  WARNING] æœªèƒ½è·å–ä»»ä½•è®ºæ–‡ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºè¯¥å¹´ä»½æš‚æ— æ•°æ®æˆ–é…ç½®é”™è¯¯ã€‚")

        except Exception as e:
            print(f"    [âœ– ERROR] æµ‹è¯• ICLR {year} (å…ƒæ•°æ®) æ—¶é­é‡ä¸¥é‡é”™è¯¯: {e}")
            logger.error(f"ICLR {year} metadata test failed.", exc_info=True)

        # å‹å¥½ç­‰å¾…
        time.sleep(2)

        # --- é˜¶æ®µäºŒ: æ·±åº¦æµ‹è¯• (å®Œæ•´ä¿¡æ¯) ---
        print(f"  [â–¶ Phase 2/2] æ­£åœ¨æµ‹è¯•: å®Œæ•´ä¿¡æ¯è·å– (Limit: {FULL_DETAIL_PAPER_LIMIT})")
        try:
            task_info_full = base_task_info.copy()
            task_info_full.update({
                'limit': FULL_DETAIL_PAPER_LIMIT,
                'fetch_reviews': True
            })

            logger.info(f"ä¸º ICLR {year} (å®Œæ•´ä¿¡æ¯æµ‹è¯•) ç”Ÿæˆçš„é…ç½®: {task_info_full}")

            scraper_full = IclrScraper(task_info_full, logger)
            results_full = scraper_full.scrape()

            if results_full:
                print(f"    [âœ” SUCCESS] æˆåŠŸè·å– {len(results_full)} ç¯‡è®ºæ–‡çš„å®Œæ•´ä¿¡æ¯ã€‚")
                print("    --- æ ·æœ¬æ•°æ® (ç¬¬ä¸€ç¯‡ï¼Œåº”åŒ…å« pdf_url å’Œ reviews) ---")
                pprint(asdict(results_full[0]), indent=4, width=100)
                print("    --------------------------------------------------\n")
            else:
                print(f"    [âš  WARNING] æœªèƒ½è·å–ä»»ä½•è®ºæ–‡ã€‚")

        except Exception as e:
            print(f"    [âœ– ERROR] æµ‹è¯• ICLR {year} (å®Œæ•´ä¿¡æ¯) æ—¶é­é‡ä¸¥é‡é”™è¯¯: {e}")
            logger.error(f"ICLR {year} full detail test failed.", exc_info=True)

        # å‹å¥½ç­‰å¾…
        time.sleep(2)

    print("\n" + "=" * 80)
    print("âœ… ICLR Scraper æµ‹è¯•å¥—ä»¶æ‰§è¡Œå®Œæ¯•ã€‚")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    run_test()

# END OF FILE: src/test/test_iclr_scraper.py