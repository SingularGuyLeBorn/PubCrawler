import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ==============================================================================
# --- å®éªŒé…ç½® ---
# ==============================================================================

# 1. è®¾ç½®ç”¨äºæµ‹è¯•çš„çº¿ç¨‹æ•°åˆ—è¡¨ã€‚è„šæœ¬å°†ä¸ºåˆ—è¡¨ä¸­çš„æ¯ä¸ªå€¼è¿è¡Œä¸€æ¬¡æµ‹è¯•ã€‚
#    å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´è¿™ä¸ªåˆ—è¡¨ï¼Œä¾‹å¦‚å¢åŠ  40, 56 ç­‰ã€‚
THREADS_TO_TEST = [4, 8, 12, 16, 24, 32, 48, 64]

# 2. é€‰æ‹©ä¸€ä¸ªå›ºå®šçš„å¹´ä»½è¿›è¡Œæµ‹è¯•ï¼Œä»¥ä¿è¯æ¯æ¬¡æµ‹è¯•çš„å·¥ä½œé‡ä¸€è‡´ã€‚
#    å»ºè®®é€‰æ‹©ä¸€ä¸ªè®ºæ–‡æ•°é‡è¾ƒå¤šçš„å¹´ä»½ï¼Œå¦‚ 2024 æˆ– 2025ã€‚
YEAR_FOR_TESTING = 2024

# 3. è®¾ç½®ç”¨äºæµ‹è¯•çš„è®ºæ–‡æ•°é‡ã€‚æ•°é‡ä¸å®œè¿‡å°‘ï¼ˆæ— æ³•ä½“ç°å·®è·ï¼‰ï¼Œä¹Ÿä¸å®œè¿‡å¤šï¼ˆæµ‹è¯•æ—¶é—´å¤ªé•¿ï¼‰ã€‚
#    100-200 æ˜¯ä¸€ä¸ªæ¯”è¾ƒç†æƒ³çš„èŒƒå›´ã€‚
PAPERS_FOR_TESTING = 150

# ==============================================================================

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
ACL_BASE_URL_PATTERN = "https://aclanthology.org/volumes/{year}.acl-long/"


def get_paper_links_for_workload(year: int, limit: int):
    """
    è·å–ä¸€ä¸ªå›ºå®šçš„å·¥ä½œè´Ÿè½½ï¼ˆè®ºæ–‡é“¾æ¥åˆ—è¡¨ï¼‰ç”¨äºæ‰€æœ‰æµ‹è¯•ã€‚
    """
    target_url = ACL_BASE_URL_PATTERN.format(year=year)
    print(f"[*] å‡†å¤‡å®éªŒç¯å¢ƒ: æ­£åœ¨ä» {target_url} è·å–è®ºæ–‡åˆ—è¡¨...")

    try:
        response = requests.get(target_url, headers=HEADERS, timeout=30)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'lxml')
        link_tags = soup.select('p.d-sm-flex strong a.align-middle')
        paper_links = [urljoin(target_url, tag['href']) for tag in link_tags if f'{year}.acl-long.0' not in tag['href']]

        actual_found = len(paper_links)
        print(f"[*] æ‰¾åˆ°äº† {actual_found} ç¯‡æœ‰æ•ˆè®ºæ–‡ã€‚")

        # æ™ºèƒ½é™åˆ¶ï¼šç¡®ä¿æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œä½†åˆä¸è¶…è¿‡å®é™…æ•°é‡
        actual_limit = min(limit, actual_found)
        if actual_limit < limit:
            print(f"[*] [è­¦å‘Š] æœŸæœ›æµ‹è¯• {limit} ç¯‡ï¼Œä½†åªæ‰¾åˆ° {actual_found} ç¯‡ã€‚å°†ä»¥ {actual_limit} ç¯‡ä¸ºå‡†ã€‚")

        print(f"[*] å®éªŒå·¥ä½œè´Ÿè½½å·²ç¡®å®š: {actual_limit} ç¯‡è®ºæ–‡ã€‚")
        return paper_links[:actual_limit]
    except requests.RequestException as e:
        print(f"[!] [é”™è¯¯] å‡†å¤‡å·¥ä½œè´Ÿè½½å¤±è´¥: {e}")
        return None


def scrape_single_paper_details(url: str):
    """çˆ¬å–å•ä¸ªè¯¦æƒ…é¡µçš„æ ¸å¿ƒå‡½æ•°ã€‚åœ¨æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬åªå…³å¿ƒå®ƒæ˜¯å¦æˆåŠŸå®Œæˆã€‚"""
    try:
        # ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶ï¼Œå› ä¸ºå¹¶å‘æ—¶ç½‘ç»œå¯èƒ½ä¼šæ‹¥å µ
        response = requests.get(url, headers=HEADERS, timeout=25)
        response.raise_for_status()
        # è¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦è§£æï¼Œåªéœ€è¦ç¡®ä¿è¯·æ±‚æˆåŠŸè¿”å›å³å¯æ¨¡æ‹ŸçœŸå®è€—æ—¶
        return True
    except Exception:
        return False


def run_single_test(worker_count: int, urls_to_crawl: list):
    """
    ä½¿ç”¨æŒ‡å®šçš„çº¿ç¨‹æ•°ï¼Œå¯¹ç»™å®šçš„URLåˆ—è¡¨æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„çˆ¬å–æµ‹è¯•ã€‚
    """
    print("\n" + "-" * 60)
    print(f"ğŸ§ª æ­£åœ¨æµ‹è¯•: {worker_count} ä¸ªå¹¶å‘çº¿ç¨‹...")

    start_time = time.time()

    with ThreadPoolExecutor(max_workers=worker_count) as executor:
        futures = [executor.submit(scrape_single_paper_details, url) for url in urls_to_crawl]

        # ä½¿ç”¨tqdmæ¥å¯è§†åŒ–è¿›åº¦
        for _ in tqdm(as_completed(futures), total=len(urls_to_crawl), desc=f"   - è¿›åº¦ ({worker_count}çº¿ç¨‹)"):
            pass

    end_time = time.time()
    elapsed_time = end_time - start_time

    print(f"   -> å®Œæˆ! è€—æ—¶: {elapsed_time:.2f} ç§’")
    return elapsed_time


def main():
    """ä¸»å‡½æ•°ï¼Œè°ƒåº¦æ‰€æœ‰æµ‹è¯•å¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚"""
    print("=" * 60)
    print("      å¹¶å‘çº¿ç¨‹æ•°æ€§èƒ½ä¼˜åŒ–å™¨ for ACL Crawler")
    print("=" * 60)

    # 1. å‡†å¤‡ä¸€ä¸ªå›ºå®šçš„ã€ç”¨äºæ‰€æœ‰æµ‹è¯•çš„å·¥ä½œè´Ÿè½½
    workload_urls = get_paper_links_for_workload(YEAR_FOR_TESTING, PAPERS_FOR_TESTING)
    if not workload_urls:
        print("[!] æ— æ³•ç»§ç»­æµ‹è¯•ï¼Œå› ä¸ºæœªèƒ½è·å–åˆ°è®ºæ–‡åˆ—è¡¨ã€‚")
        return

    # 2. å¾ªç¯æ‰§è¡Œæµ‹è¯•
    experiment_results = []
    for num_threads in THREADS_TO_TEST:
        duration = run_single_test(num_threads, workload_urls)
        experiment_results.append({
            "threads": num_threads,
            "time": duration
        })
        # åœ¨æ¯æ¬¡æµ‹è¯•é—´æ­‡2ç§’ï¼Œé¿å…å¯¹æœåŠ¡å™¨é€ æˆè¿ç»­å†²å‡»
        time.sleep(2)

    # 3. åˆ†æç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š
    if not experiment_results:
        print("[!] æ²¡æœ‰å®Œæˆä»»ä½•æµ‹è¯•ã€‚")
        return

    print("\n\n" + "#" * 60)
    print("ğŸ“Š            æœ€ç»ˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
    print(f"            (æµ‹è¯•è´Ÿè½½: {len(workload_urls)} ç¯‡è®ºæ–‡)")
    print("#" * 60)
    print(f"{'çº¿ç¨‹æ•°':<10} | {'æ€»è€—æ—¶ (ç§’)':<15} | {'æ¯ç§’çˆ¬å–è®ºæ–‡æ•°':<20}")
    print("-" * 60)

    best_result = None
    best_performance = 0

    for res in experiment_results:
        threads = res['threads']
        total_time = res['time']

        if total_time > 0:
            papers_per_second = len(workload_urls) / total_time
            print(f"{threads:<10} | {total_time:<15.2f} | {papers_per_second:<20.2f}")

            if papers_per_second > best_performance:
                best_performance = papers_per_second
                best_result = res
        else:
            print(f"{threads:<10} | {total_time:<15.2f} | {'N/A'}")

    print("-" * 60)

    # 4. ç»™å‡ºæœ€ç»ˆå»ºè®®
    if best_result:
        optimal_threads = best_result['threads']
        print("\nğŸ† ç»“è®º:")
        print(f"æ ¹æ®æœ¬æ¬¡åœ¨æ‚¨å½“å‰ç½‘ç»œç¯å¢ƒä¸‹çš„å®æµ‹ç»“æœï¼š")
        print(f"å½“çº¿ç¨‹æ•°è®¾ç½®ä¸º **{optimal_threads}** æ—¶ï¼Œçˆ¬å–æ•ˆç‡æœ€é«˜ï¼Œè¾¾åˆ°äº†æ¯ç§’ **{best_performance:.2f}** ç¯‡è®ºæ–‡ã€‚")
        print(f"å»ºè®®æ‚¨åœ¨ PubCrawler çš„ YAML é…ç½®æ–‡ä»¶ä¸­å°† ACL å’Œ CVF ä»»åŠ¡çš„ `max_workers` è®¾ç½®ä¸º **{optimal_threads}**ã€‚")
    else:
        print("\n[!] æœªèƒ½ç¡®å®šæœ€ä½³çº¿ç¨‹æ•°ã€‚")

    print("#" * 60)


if __name__ == "__main__":
    main()