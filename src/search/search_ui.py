# FILE: src/search/search_ai_assistant.py (v7.3 - AI Module Separated)

import sqlite3
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from pathlib import Path
import textwrap
import time
import sys
import re
import torch
import math
from datetime import datetime
from collections import Counter
import os
from dotenv import load_dotenv

# --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘: å¯¼å…¥æ–°çš„AIæœåŠ¡æ¨¡å— ---
from src.ai.glm_chat_service import start_ai_chat_session, print_colored, Colors

# ------------------------------------

# --- é…ç½® (å¤§éƒ¨åˆ†ä¸å˜ï¼Œä½†ä¸å†éœ€è¦AI_CONTEXT_PAPERSå’ŒZHIPUAI_API_KEYçš„å…¨å±€å¯¼å…¥) ---
PROJECT_ROOT = Path(__file__).parent.parent.parent
DB_DIR = PROJECT_ROOT / "database"
SEARCH_RESULTS_DIR = PROJECT_ROOT / "search_results"
DB_PATH = DB_DIR / "papers.db"
CHROMA_DB_PATH = str(DB_DIR / "chroma_db")
MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
COLLECTION_NAME = "papers"
RESULTS_PER_PAGE = 10


# --- ã€åˆ é™¤ã€‘: ä¸å†éœ€è¦åœ¨æ­¤æ–‡ä»¶ä¸­åŠ è½½ZHIPUAI_API_KEY ---
# ZHIPUAI_API_KEY = os.getenv("ZHIPUAI_API_KEY")
# --------------------------------------------------------------------------

# --- é¢œè‰²å’Œæ‰“å°å‡½æ•° (è¿™é‡Œåªéœ€ä¿ç•™print_bannerï¼Œprint_coloredå’ŒColorsä»ai_chat_serviceå¯¼å…¥) ---
# class Colors: ... (è¿™éƒ¨åˆ†å¯ä»¥ç›´æ¥åˆ é™¤ï¼Œå› ä¸ºå®ƒç°åœ¨æ˜¯ä»ai_chat_serviceå¯¼å…¥çš„)
# def print_colored(text, color): ... (è¿™éƒ¨åˆ†å¯ä»¥ç›´æ¥åˆ é™¤)

def print_banner():
    banner_text = "--- PubCrawler v7.3: AI Research Assistant (Module Refactored) ---"
    print_colored(banner_text, Colors.HEADER)
    SEARCH_RESULTS_DIR.mkdir(exist_ok=True)
    print_colored(f"[*] ç»“æœå°†ä¿å­˜è‡³: {SEARCH_RESULTS_DIR.resolve()}", Colors.UNDERLINE)


# --- æ–‡ä»¶ä¿å­˜ã€ç»Ÿè®¡ã€åˆ†é¡µæ¨¡å— (æ— å˜åŒ–ï¼Œä½†æ³¨æ„print_coloredç°åœ¨æ˜¯å¯¼å…¥çš„) ---
def save_results_to_markdown(results, query, session_dir):
    if not results: return []
    safe_query = re.sub(r'[\\/*?:"<>|]', "", query).replace(" ", "_")[:50]
    filename = session_dir / f"search_{safe_query}.md"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(f"# æœç´¢æŸ¥è¯¢: \"{query}\"\n\n**å…±æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ç»“æœ**\n\n---\n\n")
        for idx, paper in enumerate(results, 1):
            title, authors, abstract = paper.get('title', 'N/A'), paper.get('authors', 'N/A'), paper.get('abstract',
                                                                                                         'N/A')
            conf, year = paper.get('conference', 'N/A'), paper.get('year', 'N/A')
            similarity_str = f"- **è¯­ä¹‰ç›¸ä¼¼åº¦**: {paper['similarity']:.2f}\n" if 'similarity' in paper else ""
            f.write(
                f"### {idx}. {title}\n\n- **ä½œè€…**: {authors}\n- **ä¼šè®®/å¹´ä»½**: {conf} {year}\n{similarity_str}\n**æ‘˜è¦:**\n> {abstract}\n\n---\n\n")
    print_colored(f"\n[âœ”] ç»“æœå·²æˆåŠŸä¿å­˜åˆ° Markdown æ–‡ä»¶!", Colors.OKGREEN)
    print_colored(f"      -> {filename.resolve()}", Colors.UNDERLINE)


def print_stats_summary(results):
    if not results: return
    total_found = len(results)
    print_colored("\n--- æŸ¥è¯¢ç»“æœç»Ÿè®¡ ---", Colors.HEADER)
    print(f"æ€»è®¡æ‰¾åˆ° {Colors.BOLD}{total_found}{Colors.ENDC} ç¯‡ç›¸å…³è®ºæ–‡ã€‚")
    conf_year_counter = Counter([(p.get('conference', 'N/A'), p.get('year', 'N/A')) for p in results])
    if conf_year_counter:
        print("åˆ†å¸ƒæƒ…å†µ:")
        for (conf, year), count in conf_year_counter.most_common():
            print(f"  - {conf} {year}: {count} ç¯‡")
    print_colored("--------------------", Colors.HEADER)


def interactive_pagination(results, query, session_dir):
    num_results = len(results)
    if num_results == 0: return
    print_stats_summary(results)
    total_pages, current_page = math.ceil(num_results / RESULTS_PER_PAGE), 1
    while True:
        start_idx, end_idx = (current_page - 1) * RESULTS_PER_PAGE, current_page * RESULTS_PER_PAGE
        page_results = results[start_idx:end_idx]
        print_colored(f"\n--- ç»“æœé¢„è§ˆ (ç¬¬ {current_page}/{total_pages} é¡µ) ---", Colors.HEADER)
        for i, paper in enumerate(page_results, start=start_idx + 1):
            title, authors, conf, year = paper.get('title', 'N/A'), paper.get('authors', 'N/A'), paper.get('conference',
                                                                                                           'N/A'), paper.get(
                'year', 'N/A')
            display_line = f"  {Colors.OKCYAN}{conf} {year}{Colors.ENDC} | ä½œè€…: {textwrap.shorten(authors, 70)}"
            if 'similarity' in paper: display_line = f"  {Colors.OKGREEN}ç›¸ä¼¼åº¦: {paper['similarity']:.2f}{Colors.ENDC} |" + display_line
            print(f"\n{Colors.BOLD}[{i}]{Colors.ENDC} {title}\n{display_line}")
        if current_page >= total_pages: print("\n--- å·²æ˜¯æœ€åä¸€é¡µ ---"); break
        try:
            choice = input(
                f"\næŒ‰ {Colors.BOLD}[Enter]{Colors.ENDC} ä¸‹ä¸€é¡µ, '{Colors.BOLD}s{Colors.ENDC}' ä¿å­˜, '{Colors.BOLD}ai{Colors.ENDC}' å¯¹ç»“æœæé—®, '{Colors.BOLD}q{Colors.ENDC}' è¿”å›: ").lower()
            if choice == 'q': return
            if choice == 's': break
            if choice == 'ai':
                start_ai_chat_session(results)  # <-- è°ƒç”¨æ–°çš„AIæœåŠ¡å‡½æ•°
                print_colored("\n[i] AIå¯¹è¯ç»“æŸï¼Œè¿”å›ç»“æœåˆ—è¡¨ã€‚", Colors.OKBLUE)
                continue
            current_page += 1
        except KeyboardInterrupt:
            return
    if input(f"\næ˜¯å¦å°†è¿™ {num_results} æ¡ç»“æœå…¨éƒ¨ä¿å­˜åˆ° Markdown? (y/n, é»˜è®¤y): ").lower() != 'n':
        save_results_to_markdown(results, query, session_dir)


# --- æœç´¢æ ¸å¿ƒ (æ— å˜åŒ–) ---
def keyword_search(conn, raw_query):
    COLUMN_MAP = {'author': 'authors', 'title': 'title', 'abstract': 'abstract'}
    parsed_query_parts = []
    pattern = re.compile(r'(\b\w+):(?:"([^"]*)"|(\S+))')
    remaining_query = raw_query
    for match in list(pattern.finditer(raw_query)):
        full_match_text = match.group(0)
        field_alias = match.group(1).lower()
        value = match.group(2) if match.group(2) is not None else match.group(3)
        if field_alias in COLUMN_MAP:
            db_column = COLUMN_MAP[field_alias]
            safe_value = value.replace('"', '""')
            if ' ' in value or not value.isalnum():
                parsed_query_parts.append(f'{db_column}:"{safe_value}"')
            else:
                parsed_query_parts.append(f'{db_column}:{safe_value}')
            remaining_query = re.sub(re.escape(full_match_text), '', remaining_query, 1)
    general_terms = re.findall(r'"[^"]*"|\S+', remaining_query.strip())
    for term in general_terms:
        safe_term = term.replace('"', '""')
        if term.startswith('"') and term.endswith('"'):
            parsed_query_parts.append(f'{safe_term}')
        else:
            parsed_query_parts.append(safe_term)
    final_fts_query = ' AND '.join(filter(None, parsed_query_parts))
    if not final_fts_query:
        print_colored("[!] å…³é”®è¯æœç´¢æŸ¥è¯¢ä¸ºç©ºæˆ–è§£æå¤±è´¥ï¼Œæ— æ³•æ‰§è¡Œã€‚", Colors.WARNING);
        return []
    print(f"[*] æ­£åœ¨æ‰§è¡Œå…³é”®è¯æœç´¢ (FTS5 Query: '{final_fts_query}')...")
    try:
        cursor = conn.execute(
            "SELECT title, authors, abstract, conference, year FROM papers_fts WHERE papers_fts MATCH ? ORDER BY rank",
            (final_fts_query,))
        results = [{"title": r[0], "authors": r[1], "abstract": r[2], "conference": r[3], "year": r[4]} for r in
                   cursor.fetchall()]
        return results
    except sqlite3.OperationalError as e:
        print_colored(f"[!] å…³é”®è¯æœç´¢å¤±è´¥: {e}", Colors.FAIL)
        print_colored(f"    åŸå§‹æŸ¥è¯¢: '{raw_query}'", Colors.WARNING)
        print_colored(f"    ç”Ÿæˆçš„FTS5æŸ¥è¯¢: '{final_fts_query}'", Colors.WARNING)
        print_colored("    æç¤º: FTS5æŸ¥è¯¢è¯­æ³•ä¸¥æ ¼ï¼Œè¯·æ£€æŸ¥ 'AND/OR/NOT', çŸ­è¯­å¼•å·æˆ–å­—æ®µåæ˜¯å¦æœ‰è¯¯ã€‚", Colors.WARNING);
        return []


def semantic_search(conn, collection, model, query, top_n=20):
    print(f"[*] æ­£åœ¨æ‰§è¡Œè¯­ä¹‰æœç´¢: '{query}'...")
    start_t = time.time()
    query_embedding = model.encode(query, convert_to_tensor=False)
    chroma_results = collection.query(query_embeddings=[query_embedding.tolist()], n_results=top_n)
    ids_found, distances = chroma_results['ids'][0], chroma_results['distances'][0]
    if not ids_found: return []
    placeholders = ','.join('?' for _ in ids_found)
    sql_query = f"SELECT rowid, title, authors, abstract, conference, year FROM papers_fts WHERE rowid IN ({placeholders})"
    cursor = conn.cursor()
    raw_sqlite_results = {str(r[0]): r[1:] for r in cursor.execute(sql_query, ids_found).fetchall()}
    final_results = []
    for i, paper_id in enumerate(ids_found):
        details = raw_sqlite_results.get(paper_id)
        if details:
            final_results.append(
                {"title": details[0], "authors": details[1], "abstract": details[2], "conference": details[3],
                 "year": details[4], "similarity": 1 - distances[i]})
    end_t = time.time()
    print(f"[âœ”] è€—æ—¶ {end_t - start_t:.4f} ç§’ï¼Œæ‰¾åˆ°å¹¶ç»„åˆäº† {len(final_results)} ä¸ªç»“æœã€‚")
    return final_results


# --- ä¸»ç¨‹åº (éœ€è¦è¿›è¡Œä¸€äº›è°ƒæ•´ï¼Œå› ä¸ºprint_coloredå’ŒColorsç°åœ¨ä»å¤–éƒ¨å¯¼å…¥) ---
def main():
    # ä¹‹å‰è¿™é‡Œæ˜¯æ£€æŸ¥ZHIPUAI_API_KEYï¼Œç°åœ¨ç”±ai_chat_service.pyå†…éƒ¨æ£€æŸ¥

    try:
        conn = sqlite3.connect(f"file:{DB_PATH}?mode=ro", uri=True)
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        model = SentenceTransformer(MODEL_NAME, device=device)
        client = chromadb.PersistentClient(path=CHROMA_DB_PATH, settings=Settings(anonymized_telemetry=False))
        collection = client.get_collection(name=COLLECTION_NAME)
    except Exception as e:
        print_colored(f"\n[!] æ— æ³•åˆå§‹åŒ–æ¨¡å—: {e}", Colors.FAIL); return

    session_dir = SEARCH_RESULTS_DIR / f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    session_dir.mkdir(exist_ok=True)

    print_banner()
    print_colored("\n--- æœç´¢è¯­æ³• (AIå·²é›†æˆ & FTS5å·²ä¿®æ­£) ---", Colors.OKBLUE)
    print("  - `transformer author:vaswani`   (å…³é”®è¯ + ä½œè€…å­—æ®µæœç´¢)")
    print("  - `title:\"vision transformer\"`     (ç²¾ç¡®æ ‡é¢˜æœç´¢)")
    print("  - `\"large language model\" AND efficient` (çŸ­è¯­å’Œå…³é”®è¯ç»„åˆ)")
    print(f"  - `{Colors.BOLD}sem:{Colors.ENDC} efficiency of few-shot learning` (è¯­ä¹‰æœç´¢ï¼)")

    # last_results ä¸å†éœ€è¦åœ¨æ­¤å¤„å­˜å‚¨ï¼Œå› ä¸º ai_chat_session ç›´æ¥æ¥æ”¶ç»“æœ

    while True:
        try:
            q = input(f"\nğŸ” {Colors.BOLD}è¯·è¾“å…¥æŸ¥è¯¢{Colors.ENDC} (æˆ– 'exit' é€€å‡º): ").strip()
            if not q: continue
            if q.lower() == 'exit': break

            results = []
            if q.lower().startswith('sem:'):
                semantic_query = q[4:].strip()
                if semantic_query: results = semantic_search(conn, collection, model, semantic_query)
            else:
                results = keyword_search(conn, q)

            # last_results = results # ä¸å†éœ€è¦èµ‹å€¼ç»™ last_results
            interactive_pagination(results, q, session_dir)

        except KeyboardInterrupt:
            break
        except Exception as e:
            print_colored(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", Colors.FAIL)

    conn.close()
    print("\nå†è§ï¼")


if __name__ == "__main__":
    main()