# FILE: src/search/search_local.py (v4.3 - .env & sem: disabled)

import sqlite3
import numpy as np
import requests
import time
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
import textwrap
from datetime import datetime
import re
import sys
import math
import os
from dotenv import load_dotenv

# --- é…ç½® ---
PROJECT_ROOT = Path(__file__).parent.parent.parent
DB_PATH = PROJECT_ROOT / "papers.db"
SEARCH_RESULTS_DIR = PROJECT_ROOT / "search_results"
SEARCH_RESULTS_DIR.mkdir(exist_ok=True)
PAPERS_PER_FILE = 100
RESULTS_PER_PAGE = 10

# --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä¿®æ­£äº† API_URL (v4.3) ---
# ç§»é™¤äº†æ— æ•ˆçš„ /pipeline/feature-extraction/ è·¯å¾„
# å³ä½¿æš‚æ—¶ç¦ç”¨, ä¹Ÿä¿æŒ URL æ­£ç¡®, ä»¥ä¾¿æœªæ¥å¯ç”¨
API_URL = "https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2"

# --- ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ ---
load_dotenv(dotenv_path=PROJECT_ROOT / '.env')
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
HEADERS = {"Authorization": f"Bearer {HF_API_TOKEN}"}


# --- é¢œè‰²ä»£ç  (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ) ---
class Colors:
    HEADER = '\033[95m';
    OKBLUE = '\033[94m';
    OKCYAN = '\033[96m';
    OKGREEN = '\033[92m'
    WARNING = '\033[93m';
    FAIL = '\033[91m';
    ENDC = '\033[0m';
    BOLD = '\033[1m';
    UNDERLINE = '\033[4m'


# --- è¾…åŠ©å‡½æ•° ---
def print_colored(text, color):
    if sys.stdout.isatty():
        print(f"{color}{text}{Colors.ENDC}")
    else:
        print(text)


def print_banner():
    # --- ã€ä¿®æ”¹ã€‘æ›´æ–°äº† Banner ç‰ˆæœ¬å· ---
    banner_text = ["â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
                   "â•‘    ____              __            ____                       â•‘",
                   "â•‘   / __ \\____  / /______/ __ \\__  ______  ____ _____ ___    â•‘",
                   "â•‘  / /_/ / __ \\/ / ___/ / / / / / / / __ \\/ __ `/ __ `__ \\   â•‘",
                   "â•‘ / ____/ /_/ / / /__/ / /_/ / /_/ / / / / /_/ / / / / / /   â•‘",
                   "â•‘/_/    \\____/_/\\___/_/\\___\\_\\__,_/_/ /_/\\__,_/_/ /_/ /_/    â•‘",
                   "â•‘                                                          â•‘",
                   "â•‘          Your Local Paper Search Engine v4.3 (.env)        â•‘",
                   "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"]
    for line in banner_text: print_colored(line, Colors.HEADER)
    print()


def parse_advanced_query(query: str):
    # FTS5 æ”¯æŒ AND å’Œ NOT (ä½† + å’Œ - æ›´æ–¹ä¾¿)
    query = query.replace(' +', ' AND ').replace(' -', ' NOT ')

    # å°†ç”¨æˆ·å‹å¥½çš„ author: æ˜ å°„åˆ°æ•°æ®åº“å­—æ®µ authors:
    # FTS5 ä¼šè‡ªåŠ¨å¤„ç† 'authors:hinton' è¿™æ ·çš„è¯­æ³•
    # --- ã€ä¿®æ”¹ã€‘å¢åŠ äº† re.IGNORECASE ---
    query = re.sub(r'author:(\S+)', r'authors:\1', query, flags=re.IGNORECASE)
    query = re.sub(r'title:(\S+)', r'title:\1', query, flags=re.IGNORECASE)
    return query


def keyword_search_db(conn, raw_query):
    advanced_query = parse_advanced_query(raw_query)
    print(f"[*] æ­£åœ¨æ‰§è¡Œå…³é”®è¯æœç´¢: '{advanced_query}'...")
    start_t = time.time()
    try:
        cursor = conn.execute(
            "SELECT title, authors, abstract, conference, year, pdf_url, source_file FROM papers_fts WHERE papers_fts MATCH ? ORDER BY rank",
            (advanced_query,))
        results = cursor.fetchall()
        end_t = time.time()
        count = len(results)
        print(f"[âœ”] è€—æ—¶ {end_t - start_t:.4f} ç§’ï¼Œæ‰¾åˆ° {Colors.BOLD}{Colors.OKGREEN}{count}{Colors.ENDC} ä¸ªç»“æœã€‚")
        return results
    except sqlite3.OperationalError as e:
        # --- ã€ä¿®æ”¹ã€‘å¢åŠ äº†æ›´è¯¦ç»†çš„é”™è¯¯æç¤º ---
        print_colored(f"[!] æœç´¢è¯­æ³•é”™è¯¯: {e}", Colors.FAIL)
        print_colored("    æç¤º: ç¡®ä¿ AND/NOT/OR é€»è¾‘æ­£ç¡®ï¼Œæˆ–å­—æ®µå(title:/author:)åæœ‰å†…å®¹ã€‚", Colors.WARNING)
        return []


def get_embedding_from_api(text: str):
    """(æ­¤å‡½æ•°åœ¨ v4.3 ä¸­æœªè¢« main() è°ƒç”¨)"""
    payload = {"inputs": text, "options": {"wait_for_model": True}}
    try:
        response = requests.post(API_URL, headers=HEADERS, json=payload, timeout=20)

        # --- ã€ä¿®æ”¹ã€‘å¢åŠ äº†æ›´æ˜ç¡®çš„é”™è¯¯å¤„ç† ---
        if response.status_code == 401:
            print_colored("\n[!] API é”™è¯¯: 401 - Token æ— æ•ˆã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ HF_API_TOKENã€‚", Colors.FAIL)
            return None
        if response.status_code == 404:
            print_colored(f"\n[!] API é”™è¯¯: 404 - æœªæ‰¾åˆ°æ¨¡å‹ã€‚è¯·æ£€æŸ¥ API_URL: {API_URL}", Colors.FAIL)
            return None

        response.raise_for_status()  # æ•è· 429 (é™é€Ÿ), 5xx (æœåŠ¡å™¨é”™è¯¯) ç­‰

        result = response.json()
        if isinstance(result, list) and isinstance(result[0], list):
            return np.array(result[0], dtype=np.float32)

    except requests.exceptions.RequestException as e:
        print_colored(f"\n[!] API è¯·æ±‚å¤±è´¥: {e}", Colors.FAIL)
        return None
    except Exception as e:
        print_colored(f"\n[!] API å“åº”å¤„ç†å¤±è´¥: {e}", Colors.FAIL)
        return None
    return None


def semantic_search_db(conn, query, top_k=50):
    """(æ­¤å‡½æ•°åœ¨ v4.3 ä¸­æœªè¢« main() è°ƒç”¨)"""
    print(f"[*] æ­£åœ¨æ‰§è¡Œè¯­ä¹‰æœç´¢: '{query}'...")
    start_t = time.time()

    query_embedding = get_embedding_from_api(query)
    if query_embedding is None:
        print_colored("[!] é”™è¯¯: ä» API è·å–æŸ¥è¯¢å‘é‡å¤±è´¥ã€‚è¯·æ£€æŸ¥æ‚¨çš„ Token å’Œç½‘ç»œè¿æ¥ã€‚", Colors.FAIL)
        return []

    cursor = conn.cursor()
    cursor.execute("SELECT paper_id, embedding FROM embeddings")
    all_embeddings_data = cursor.fetchall()
    if not all_embeddings_data:
        # --- ã€ä¿®æ”¹ã€‘å¢åŠ äº†å¯¹ embedding è¡¨ä¸ºç©ºçš„æ£€æŸ¥ ---
        print_colored("[!] é”™è¯¯: æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°è¯­ä¹‰å‘é‡ã€‚", Colors.FAIL)
        print_colored("    è¯·å…ˆè¿è¡Œ embedder.py ç”Ÿæˆå‘é‡ã€‚", Colors.WARNING)
        return []

    paper_ids = [row[0] for row in all_embeddings_data]
    db_embeddings = np.array([np.frombuffer(row[1], dtype=np.float32) for row in all_embeddings_data])

    similarities = cosine_similarity(query_embedding.reshape(1, -1), db_embeddings)[0]
    top_k_indices = np.argsort(similarities)[-top_k:][::-1]
    top_paper_ids = [paper_ids[i] for i in top_k_indices]
    top_scores = [similarities[i] for i in top_k_indices]

    placeholders = ','.join('?' for _ in top_paper_ids)
    sql = f"SELECT rowid, title, authors, abstract, conference, year, pdf_url, source_file FROM papers_fts WHERE rowid IN ({placeholders})"

    # FTS rowid æ˜ å°„åˆ° (title, authors, ...)
    raw_results_dict = {row[0]: row[1:] for row in cursor.execute(sql, top_paper_ids).fetchall()}

    final_results = []
    # æŒ‰ç›¸ä¼¼åº¦é¡ºåºé‡æ–°ç»„åˆç»“æœ
    for i, paper_id in enumerate(top_paper_ids):
        details = raw_results_dict.get(paper_id)
        if details:
            # (title, authors, abstract, conf, year, pdf, src)
            # åœ¨æ ‡é¢˜å‰åŠ å…¥ç›¸ä¼¼åº¦å¾—åˆ†
            scored_title = f"(ç›¸ä¼¼åº¦: {top_scores[i]:.2f}) {details[0]}"
            final_results.append((scored_title,) + details[1:])

    end_t = time.time()
    print(f"[âœ”] è€—æ—¶ {end_t - start_t:.4f} ç§’ï¼Œæ‰¾åˆ° {len(final_results)} ä¸ªè¯­ä¹‰ç›¸å…³ç»“æœã€‚")
    return final_results


def interactive_pagination(results, query):
    num_results = len(results)
    if num_results == 0: return "quit"
    total_pages = math.ceil(num_results / RESULTS_PER_PAGE)
    current_page = 1
    while True:
        start_idx = (current_page - 1) * RESULTS_PER_PAGE
        end_idx = start_idx + RESULTS_PER_PAGE
        page_results = results[start_idx:end_idx]
        print_colored(f"\n--- ç»“æœé¢„è§ˆ (ç¬¬ {current_page}/{total_pages} é¡µ) ---", Colors.HEADER)
        for i, row in enumerate(page_results, start=start_idx + 1):
            print(f"\n{Colors.BOLD}[{i}]{Colors.ENDC} {row[0]}")
            print(f"  {Colors.OKCYAN}{row[3]} {row[4]}{Colors.ENDC} | ä½œè€…: {textwrap.shorten(row[1], 80)}")
            if row[5]: print(f"  PDF: {row[5]}")

        if current_page >= total_pages:
            print("\n--- å·²æ˜¯æœ€åä¸€é¡µ ---")
            return "end_of_list"
        try:
            choice = input(
                f"\næŒ‰ {Colors.BOLD}[Enter]{Colors.ENDC} ä¸‹ä¸€é¡µ, '{Colors.BOLD}s{Colors.ENDC}' ä¿å­˜, '{Colors.BOLD}q{Colors.ENDC}' é€€å‡º: ").lower()
            if choice == 'q':
                return "quit"
            elif choice == 's':
                return "save"
            current_page += 1
        except KeyboardInterrupt:
            break
    return "quit"


def save_results_to_files(results, query, session_dir):
    safe_query = re.sub(r'[\\/*?:"<>|]', "", query).replace(" ", "_")
    num_results = len(results)
    num_files = (num_results + PAPERS_PER_FILE - 1) // PAPERS_PER_FILE
    saved_files = []
    for i in range(num_files):
        start_index = i * PAPERS_PER_FILE
        chunk = results[start_index: start_index + PAPERS_PER_FILE]
        filename = session_dir / f"search_{safe_query[:50]}{'_part_' + str(i + 1) if num_files > 1 else ''}.md"
        saved_files.append(filename)
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# æœç´¢: \"{query}\"\n\n**æ‰¾åˆ° {num_results} ç»“æœ (éƒ¨åˆ† {i + 1}/{num_files})**\n\n---\n\n")
            for idx, row in enumerate(chunk, start=start_index + 1):
                title, authors, abstract, conf, year, pdf, src = row
                f.write(f"### {idx}. {title}\n\n- **ä½œè€…**: {authors}\n- **ä¼šè®®**: {conf} {year}\n")
                if pdf and str(pdf).strip(): f.write(f"- **PDF**: [{pdf}]({pdf})\n")
                f.write(f"\n**æ‘˜è¦:**\n> {abstract}\n\n*æ¥æº: `{src}`*\n\n---\n\n")
    return saved_files


def main():
    if not HF_API_TOKEN:
        print_colored("é”™è¯¯: æœªèƒ½ä» .env æ–‡ä»¶ä¸­åŠ è½½ HF_API_TOKENã€‚", Colors.FAIL)
        print_colored("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºäº† .env æ–‡ä»¶ï¼Œå¹¶å†™å…¥ HF_API_TOKEN=\"hf_...\"", Colors.FAIL)
        return
    if not DB_PATH.exists():
        print_colored(f"\n[!] æ•°æ®åº“ä¸å­˜åœ¨: {DB_PATH}", Colors.FAIL)
        return

    # ä»¥åªè¯»æ¨¡å¼è¿æ¥
    conn = sqlite3.connect(f"file:{DB_PATH}?mode=ro", uri=True)
    session_dir = SEARCH_RESULTS_DIR / f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    session_dir.mkdir(exist_ok=True)

    print_banner()
    print(f"[*] ç´¢å¼•å·²åŠ è½½: {Colors.OKCYAN}{DB_PATH.resolve()}{Colors.ENDC}")
    print_colored(f"[*] ç»“æœå°†ä¿å­˜è‡³: {session_dir.resolve()}", Colors.UNDERLINE)

    # --- ã€ä¿®æ”¹ã€‘æ‰©å……äº†æœç´¢è¯­æ³•ç¤ºä¾‹ ---
    print_colored("\n--- å…³é”®è¯æœç´¢è¯­æ³• (FTS5) ---", Colors.OKBLUE)
    print("  - `transformer`                 (åŒ…å« transformer)")
    print("  - `\"large language model\"`      (åŒ…å«çŸ­è¯­)")
    print("  - `author:hinton`               (ä½œè€…å­—æ®µåŒ…å« hinton)")
    print("  - `title:attention`             (æ ‡é¢˜å­—æ®µåŒ…å« attention)")
    print("  - `author:hinton + title:rnn`   (ä½œè€… hinton ä¸” æ ‡é¢˜ rnn)")
    print("  - `transformer - author:vaswani` (åŒ…å« transformer ä½†æ’é™¤ä½œè€… vaswani)")
    print("  - `(author:lecun OR author:bengio) + cnn` (å¤æ‚é€»è¾‘)")
    print_colored("\n  - `sem:...` (è¯­ä¹‰æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨)\n", Colors.WARNING)

    while True:
        try:
            q = input(f"ğŸ” {Colors.BOLD}è¯·è¾“å…¥å…³é”®è¯{Colors.ENDC} (æˆ– 'exit' é€€å‡º): ").strip()
            if not q: continue
            if q.lower() == 'exit': break

            results = []

            # --- ã€ä¿®æ”¹ã€‘ç¦ç”¨äº†è¯­ä¹‰æœç´¢ ---
            if q.lower().startswith('sem:'):
                print_colored("\n[!] è¯­ä¹‰æœç´¢ (sem:) åŠŸèƒ½æš‚æ—¶ç¦ç”¨ã€‚", Colors.WARNING)
                print_colored("    è¯·ä½¿ç”¨ä¸Šæ–¹çš„å…³é”®è¯æœç´¢è¯­æ³• (å¦‚: title:..., author:..., +, -)ã€‚\n", Colors.WARNING)
                continue  # è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œç­‰å¾…æ–°è¾“å…¥
            else:
                results = keyword_search_db(conn, q)

            if not results: continue

            pagination_result = interactive_pagination(results, q)

            if pagination_result in ["save", "end_of_list"]:
                if input(f"\nä¿å­˜è¿™ {len(results)} æ¡ç»“æœ? (y/n, é»˜è®¤y): ").lower() != 'n':
                    files = save_results_to_files(results, q, session_dir)
                    print_colored("\n[âœ”] ç»“æœå·²ä¿å­˜!", Colors.OKGREEN)
                    for f in files: print_colored(f"      -> {f.resolve()}", Colors.UNDERLINE)

            print()  # åœ¨ä¸¤æ¬¡æœç´¢ä¹‹é—´æ·»åŠ ä¸€ä¸ªç©ºè¡Œ

        except KeyboardInterrupt:
            break
        except Exception as e:
            print_colored(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", Colors.FAIL)

    conn.close()
    print("\nå†è§ï¼")


if __name__ == "__main__":
    main()